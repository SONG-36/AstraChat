# 1 引言

## 1.1 文档目的

​	本《需求规格说明书》（Software Requirements Specification，SRS）用于明确 AstraChat 项目的业务目标和功能/非功能需求，为后续的系统架构设计、详细设计与实现提供统一的依据。

​	本项目的目标是：
在 AWS 云平台上构建一个 **面向 Web / 小程序 / 业务后台的 AI 智能客服中间件**，采用 Serverless 架构（API Gateway + Lambda + DynamoDB + S3 等），对接主流大语言模型（如 OpenAI），以 **ADAS 风格的模块化中间件体系** 实现可扩展、可维护的 AI 对话能力。

​	本说明书面向如下角色：

- 系统架构设计人员：根据本说明书设计整体架构和模块划分
- 开发人员：根据需求实现核心引擎、中间件和能力模块
- 测试人员：基于需求条目设计测试用例，验证系统功能
- 运维 / DevOps 人员：了解系统使用场景、接口规范与非功能要求
- 潜在合作方 / 招聘方：通过该文档快速理解项目目标与能力范围

## 1.2 项目范围

AstraChat 是一个 **“AI 对话能力中间件”**，而不是单一的前端聊天应用。
其范围包括：

- 提供标准化 HTTP 接口 / API 接口，让外部系统可以接入 AI 对话服务
- 支持对话上下文记忆、知识库增强（RAG）、工具调用等能力
- 通过 AWS Serverless 部署，实现低成本、易扩展、易维护
- 使用模块化中间件架构，便于未来扩展多模态（图像 / 语音）与多业务场景

不在本项目当前范围内的部分包括（可作为未来扩展）：

- 完整的前端 UI（Web、移动 App）
- 大规模多租户计费结算系统
- 复杂的用户权限与组织架构管理
- 实时语音通话 / 视频通话类场景

## 1.3 术语与缩写

为避免歧义，本项目中涉及的主要术语、缩写说明如下：

- **AstraChat**：本项目名称，指基于 AWS Serverless 的 AI 中间件系统
- **LLM（Large Language Model）**：大语言模型，如 OpenAI GPT 系列
- **RAG（Retrieval-Augmented Generation）**：检索增强生成，通过向量检索获取相关文档并与对话上下文拼接后再交给 LLM 生成回复
- **Serverless**：无服务器架构，主要指使用 AWS Lambda、API Gateway 等服务进行按需计算
- **API Gateway**：AWS 的 API 网关服务，用于统一接收 HTTP/REST 请求并转发到 Lambda
- **Lambda**：AWS Lambda 函数计算服务，本项目的核心执行单元
- **DynamoDB**：AWS NoSQL 数据库服务，用于存储会话历史、用户信息等
- **S3（Simple Storage Service）**：AWS 对象存储服务，用于存放知识库文档、配置文件等
- **Middleware（中间件）**：在请求生命周期中依次执行的处理模块，例如输入规范化、记忆加载、RAG 检索、决策、LLM 调用等
- **Context（上下文对象）**：在 Pipeline 中传递的统一状态对象，包含输入消息、用户信息、会话历史、RAG 结果、LLM 输出等
- **Tool / Function Calling（工具调用）**：LLM 通过结构化输出触发外部业务接口调用的能力，如订单查询、库存查询等
- **NFR（Non-Functional Requirements）**：非功能需求，如性能、可用性、可维护性、安全性要求等

# 2 整体描述（Overall Description）

本章从系统背景、用户角色、使用场景、功能概览与约束条件等维度，给出 AstraChat 的整体描述，帮助读者从宏观层面对系统有清晰认识。

## 2.1 系统背景（System Background）

随着大语言模型（LLM）能力的提升，越来越多的企业希望为其业务系统增加：

- 智能问答
- 智能客服
- 文档搜索问答
- 自动化工具调用
- 业务流程辅助决策

但多数企业缺乏：

- 架构能力
- AI 交互能力
- 可靠的云部署方案
- 优雅的工程设计

因此需要一个 **可复用、可扩展、易部署的 AI 中间件系统**，将常见能力做好封装，让业务系统只需接入一个 API 即可使用智能对话功能。

AstraChat 正是为了解决这些痛点而设计，它基于：

- **AWS Serverless**（成本低、免运维、可扩展）
- **模块化中间件架构（ADAS 风格）**（易维护、易扩展）
- **标准 API 接口**（可快速集成到任意 Web / App / 后端系统）

AstraChat 旨在成为企业或个人开发者可以“直接使用的通用 AI 能力层（AI Middleware Layer）”。

## 2.2 用户角色（Actors / User Classes）

本系统面向的主要用户角色包括：

### **（1）普通终端用户（End User）**

通过 Web、小程序、App 或业务系统看到的是“聊天窗口”或“智能问答界面”。
他们并不直接接触 AstraChat，而是通过业务系统间接使用。

目的：

- 提出问题
- 查询业务信息
- 与 AI 进行交流

### **（2）业务系统开发者（Client Developer）**

将 AstraChat 作为 **后端 AI 能力服务** 接入自己系统。

他们需要：

- 一个简单稳定的 HTTP API
- 可传入用户 ID、消息、业务参数
- 稳定的响应（无须关心内部架构）

典型场景：

- 公众号客服
- 商城订单查询助手
- 技术文档智能问答
- 小程序在线客服
- 企业内部机器人

### **（3）系统维护者 / DevOps（Infrastructure / Ops）**

负责：

- 监控 Lambda、DynamoDB、API Gateway 使用情况
- 成本控制
- 日志追踪与错误排查
- 环境变量管理（dev / prod）

### **（4）架构设计人员（Architect）**

我本人以及未来的团队需要根据需求制定架构、扩展能力模块并长期维护系统。

## 2.3 典型使用场景（Use Cases）

本系统初始版本（V1）支持以下典型场景：

### **场景 1：标准对话问答（LLM 直答）**

用户向系统提出问题，系统直接调用模型生成回答。

输入示例：

```
{"userId": "u123", "message": "你能帮我写一段介绍吗？"}
```

### **场景 2：基于知识库的问答（RAG）**

用户查询企业内部知识，如：

- 操作手册内容
- 公司政策
- 产品文档

系统自动检索相关内容并与 LLM 一起生成回答。

### **场景 3：业务工具调用（Tool Calling）**

常见例子：

- 订单查询
- 库存查询
- 客户状态查询

流程：

1. 用户：“查一下我订单 12345 的状态”
2. 系统 → DecisionModule 识别为工具调用
3. ToolsModule 调用业务 API
4. LLM 整理成自然语言并返回

### **场景 4：多轮对话（Conversation Memory）**

系统能够记住用户前几轮的消息历史，提供连续、自然的对话体验。
历史记录存储在 DynamoDB。

### **场景 5：系统能力扩展（模块插拔）**

未来可扩展：

- 图像输入（Vision）
- 语音输入（Speech）
- 多业务系统工具调用

中间件架构允许“无缝衔接”。

### **场景 6：AI → 人工客服的转接（Human Handoff / Escalation）**

在某些业务场景下，AI 无法完全处理用户的请求，本系统必须支持人工客服接入流程，包括以下情况：

- 用户明确要求“转人工客服”“人工帮助”
- AI 在多轮对话中无法理解意图
- 工具调用失败超过重试次数
- 涉及支付、身份验证、投诉等敏感场景
- 用户情绪激动，需要人工处理

系统行为：

1. DecisionModule 判断是否需要人工介入

2. 系统返回统一结构的 **handoff 信号** 给上层业务（例如：

   ```
   {"handoff": true, "reason": "CONFUSION_AFTER_3_ATTEMPTS"}
   ```

3. 业务系统自动将用户会话切换到人工客服队列

4. 人工客服系统可读取该用户的上下文与历史对话（从 DynamoDB 获取）

该功能不在 V1 实现，但属于 **明确的未来能力边界**，系统架构会为其预留扩展点。

## 2.4 功能概览（System Features Overview）

当前版本（V1）的核心功能包括：

- **文本输入解析**
- **对话上下文记忆（Memory）**
- **知识库增强（RAG）**
- **工具调用（Tools）**
- **模型调用（LLM Provider）**
- **中间件 Pipeline 执行**
- **统一错误格式**
- **统一响应格式**
- **基础日志（CloudWatch）**

未来版本将扩展：

- 图片理解（Vision）
- 语音识别 / 语音回答
- 多租户（SaaS）
- 权限系统
- 业务插件市场

## 2.5 约束条件（Constraints）

本系统运行在 AWS Serverless 环境，因此有以下限制：

### **（1）Lambda 执行时间限制**

- 默认 3~15 秒（根据配置）
- 过长的模型调用需避免阻塞

### **（2）API Gateway 超时时间为 29 秒**

不能执行超过 29 秒的同步任务。

### **（3）成本限制**

- 模型调用具备显著成本
- DynamoDB 按读写计费
- S3 按用量存储计费

系统必须具有成本可控性。

### **（4）依赖外部 LLM 服务**

外部 API（OpenAI、Claude）可能：

- 超时
- 限流
- 网络抖动

因此必须具备重试机制与错误兜底。

### **（5）安全性要求**

- API Key 不可泄露
- Lambda 环境变量需加密
- 跨域与访问控制需配置规范

## 2.6 假设与依赖（Assumptions and Dependencies）

为了系统正常工作，做出如下假设：

- 调用方能够提供用户唯一 ID（userId）
- 调用方能够通过 HTTPS 调用 AstraChat API
- AWS 账号权限已配置（Lambda、API Gateway、DynamoDB、S3）
- 外部模型服务（OpenAI、Claude）稳定可用
- 开发者具备基本的 Node.js / AWS CLI 使用能力

系统依赖：

- AWS Lambda
- API Gateway
- DynamoDB
- S3
- CloudWatch
- 外部 LLM 服务

# 3 功能需求（Functional Requirements, FR）

本章定义 AstraChat 系统必须具备的全部功能需求，包括输入处理、对话记忆、知识库增强、工具调用、LLM 调用、人工客服转接等核心能力。

## 3.1 **输入解析与请求规范化（Input Processing）**

### **FR-01 系统必须接受来自 API Gateway 的 JSON 输入**

输入格式：

```json
{
  "userId": "string",
  "message": "string",
  "metadata": { ... }     // 可选
}
```

要求：

- 未提供 `userId` → 返回结构化错误
- 未提供 `message` → 返回结构化错误
- `message` 必须为字符串类型

### **FR-02 系统必须支持对输入文本进行规范化处理**

包括但不限于：

- 去除首尾空白
- 合并多余空格
- 限制输入最大长度（默认 2048 字符）
- 未来预留语言检测（中、英等）

### **FR-03 系统必须生成 Trace ID**

每次请求生成唯一 traceId，用于日志、排错、成本跟踪。

示例：

```js
ctx.traceId = "req_20250102_abcdef123456"
```

## 3.2 **对话上下文记忆（Conversation Memory）**

### **FR-04 系统必须基于 userId 读取历史对话记录**

从 DynamoDB 获取用户的历史会话摘要，写入：

```js
ctx.session.history = [...]
```

### **FR-05 系统必须在回复完成后，将最新的对话摘要写回 DynamoDB**

系统需记录：

- 用户提问
- 系统回答（可摘要）
- 时间戳
- traceId

用于多轮对话与后续人工介入查看。

### **FR-06 系统必须支持记忆长度控制策略**

例如：

- 默认记住最近 N 条
- 或按 token 限制过滤

避免上下文过大导致模型成本增加。

## 3.3 **知识库增强（RAG — Retrieval-Augmented Generation）**

### **FR-07 系统必须支持可选的知识检索流程**

根据用户输入执行：

- 关键词检索或
- Embedding 向量检索（未来）

检索数据来源：

- S3 知识库存储
- 外部向量数据库（预留）

### **FR-08 系统必须将 RAG 结果写入 ctx.rag**

格式示例：

```js
ctx.rag = {
  documents: [...],
  contextText: "拼接后的文档内容"
}
```

### **FR-09 在检索失败时系统必须具备降级机制**

例如：

- S3 访问失败
- 向量库异常

系统继续流程，但不附加 RAG 上下文。

## 3.4 **工具调用（Tool Calling）**

### **FR-10 系统必须支持根据输入意图决定是否触发工具调用**

典型关键字：

- “查订单”
- “订单状态”
- “库存”
- “物流状态”

DecisionModule 需识别用户意图并设置：

```js
ctx.route = "TOOL_ORDER_QUERY"
```

### **FR-11 工具调用模块必须封装在独立模块内**

如：

- `/src/modules/tools/orderQuery.js`

要求：

- 输入结构化
- 输出结构化
- 错误抛出可被 Engine 捕获

### **FR-12 工具调用失败时必须进行有限次数重试**

默认：

- 3 次重试
- 每次间隔指数退避（如 200ms → 400ms → 800ms）

### **FR-13 工具调用返回结果必须与 LLM 结合**

例如工具返回：

```js
{ "orderStatus": "已发货", "expectedTime": "2天内" }
```

LLMModule 需将其转化为自然语言回复：

“您的订单已发货，预计 2 天后送达。”

## 3.5 **模型调用（LLM Provider）**

### **FR-14 系统必须能调用至少一个外部 LLM（如 OpenAI）**

通过 Provider 层封装：

```js
llmProvider.generate(prompt)
```

### **FR-15 模型调用必须带完整上下文**

包括：

- 用户最新问题
- 历史对话摘要
- RAG 文档拼接
- 工具输出（如有）

### **FR-16 模型调用失败时必须支持自动重试**

失败原因：

- 超时
- 模型限流
- 网络异常

重试策略：指数退避，最多 N 次（默认 2）。

### **FR-17 系统必须提供统一错误格式**

例如：

```js
{
  "success": false,
  "traceId": "...",
  "error": {
     "code": "LLM_TIMEOUT",
     "message": "模型响应超时"
  }
}
```

## 3.6 **输出与响应格式（Output Response）**

### **FR-18 系统必须返回统一 JSON 格式**

包括：

- success
- traceId
- data
- error（可选）

### **FR-19 在正常情况下必须返回自然语言回复**

格式：

```js
{
  "success": true,
  "traceId": "...",
  "data": { "answer": "……" }
}
```

## 3.7 **人工客服转接（Human Handoff / Escalation）**

### **FR-20 用户主动要求人工客服时，系统必须能识别意图**

识别关键词：

- “人工客服”
- “接入人工”
- “找真人服务”

设置：

```js
ctx.route = "HANDOFF"
```

### **FR-21 AI 多次无法理解意图时，系统必须触发自动人工转接**

如：

- 连续 3 次模型置信度过低
- 连续 3 次模型输出“无法理解”

系统必须返回：

```json
{"handoff": true, "reason": "LOW_CONFIDENCE"}
```

### **FR-22 工具调用失败（超过重试次数）时必须允许人工接管**

例如：

```js
ctx.handoff = { "reason": "TOOL_FAILURE" }
```

### **FR-23 系统必须将对话上下文提供给人工客服系统**

通过 DynamoDB：

```js
session.history
user metadata
traceId
```

### **FR-24 系统必须支持业务系统自行接入人工客服队列**

AstraChat 不负责实现坐席系统，但必须提供标准 handoff 数据。

## 3.8 **日志与监控（Logging & Observability）**

### **FR-25 系统必须在 CloudWatch 中记录关键日志**

包括：

- traceId
- userId（脱敏）
- route（LLM / RAG / TOOL / HANDOFF）
- 执行耗时
- 错误堆栈（如有）

### **FR-26 系统必须记录模型调用的 token 消耗（未来版本）**

用于成本控制。

## 3.9 **错误与异常处理（Error Handling）**

### **FR-27 系统必须对所有中间件异常进行捕获**

且转化为结构化错误响应。

### **FR-28 系统必须区分可恢复与不可恢复错误**

可恢复：

- LLM 超时
- 工具调用失败
- 网络抖动

不可恢复：

- 输入格式无效
- 系统内部严重错误

### **FR-29 必须对输入无效情况返回明确错误提示**

示例：

```js
error.code = "BAD_REQUEST"
error.message = "'message' is required"
```

# 4 非功能需求（Non-Functional Requirements, NFR）

​	本章定义 AstraChat 在性能、可扩展性、可维护性、安全性、成本、容错性、可观测性等方面必须满足的标准。
这些要求确保系统不仅“能跑”，而且“能稳定运行、能规模化、能被企业接受”。

## **4.1 性能需求（Performance Requirements）**

### **NFR-01 系统响应时间不得超过 3 秒（常规文本对话）**

- 绝大部分文本对话应在 **1–3 秒** 内完成。
- 超过 5 秒视为性能异常须记录日志。

### **NFR-02 API Gateway 超时时间必须在 29 秒内完成处理**

这是 AWS 的硬性限制，因此：

- LLM 调用必须在 Lambda 内完成
- 不允许执行长耗时任务
- 超时任务必须提前中断并返回错误结构

### **NFR-03 LLM 调用必须具备 95%+ 的成功率（含重试）**

如果外部 LLM 调用失败，应由系统重试机制保证成功率提升。

### **NFR-04 系统必须支持至少 100 QPS（未来水平），当前目标 10 QPS**

- Serverless 架构天然扩展，但需确保模块设计不会阻塞并发。

## **4.2 可扩展性（Scalability Requirements）**

### **NFR-05 系统必须支持模块级水平扩展**

包括：

- 增加新中间件（如情绪分析）
- 扩展 RAG Source（向量数据库）
- 增加工具调用类型
- 增加模型 Provider（OpenAI → Claude → DeepSeek）

架构不得因新增模块需要大规模重构。

### **NFR-06 Context 对象必须可扩展**

`ctx.xxx` 字段必须支持按模块动态扩展，而不会导致耦合。

### **NFR-07 知识库存储必须支持多源扩展**

例如：

- S3 文档
- 外部知识库 API
- 向量数据库（Pinecone / Weaviate / Faiss）

## **4.3 可维护性（Maintainability Requirements）**

### **NFR-08 代码必须具有明确的模块边界**

目录结构必须采用清晰分层：

```
/core  
/middleware  
/providers  
/modules  
/utils  
```

### **NFR-09 中间件必须职责单一（Single Responsibility）**

每个 Middleware 只能完成一种处理任务，例如：

- 输入规范化
- RAG 检索
- 记忆加载
- 工具调用决策

不得出现“多功能中间件”。

### **NFR-10 所有模块必须有日志、错误边界、输入输出定义**

以便于维护、调试和扩展。

### **NFR-11 代码必须提供基础单元测试（未来版本）**

覆盖：

- 输入解析
- RAG 模块
- 工具调用模块
- Provider 封装
- Pipeline 执行流程

单测覆盖率建议低版本 40%，未来 70%。

## **4.4 安全性（Security Requirements）**

### **NFR-12 所有 API 调用必须通过 HTTPS**

明文 HTTP 不允许。

### **NFR-13 访问 LLM 所需的 API Key 必须存储在 Lambda 环境变量中，不可硬编码**

且需：

- 加密
- 不写入日志
- 不公开给调用方

### **NFR-14 跨域访问（CORS）必须安全配置**

限制来源域名，避免任意请求。

### **NFR-15 系统不得返回敏感内部错误给前端**

如：

- 堆栈
- AWS 内部资源 ID
- 系统路径

必须统一结构化错误返回。

### **NFR-16 人工客服相关的数据必须安全存储**

包括：

- 用户历史对话
- 敏感业务参数

遵循最小权限原则（Least Privilege IAM）。

## **4.5 容错性和高可用（Fault Tolerance & Reliability）**

### **NFR-17 所有外部调用必须具备自动重试机制**

如：

- LLM 调用
- 工具调用
- S3 / DynamoDB 调用

采用指数退避策略。

### **NFR-18 系统必须区分可恢复与不可恢复错误**

可恢复错误 → Retry
不可恢复 → 返回 HANDOFF / Error

### **NFR-19 DynamoDB 存储必须具备自动容错能力**

利用 DynamoDB 自身的高可用特性，无需人工干预。

## **4.6 可观测性（Observability Requirements）**

### **NFR-20 系统必须记录每次请求的完整调用链**

包括：

- traceId
- 输入消息摘要
- 执行路径（LLM / RAG / TOOL / HANDOFF）
- 耗时
- LLM token 使用量（未来）

### **NFR-21 CloudWatch 必须记录关键错误事件**

如：

- 工具调用失败次数
- RAG 检索失败
- LLM 超时
- 人工转接事件

### **NFR-22 系统必须支持基本的指标监控（Metrics）**

未来扩展：

- 每日请求量
- LLM 成本
- 人工转接率
- RAG 使用频率

## **4.7 成本控制（Cost Requirements）**

### **NFR-23 系统必须能在低基础成本下运行**

Serverless 架构允许按需计费。

### **NFR-24 必须限制 LLM prompt 大小**

通过：

- 会话摘要
- Token 剪裁
- RAG 精选文档

避免不必要的成本消耗。

### **NFR-25 必须可切换多模型 Provider 以降低成本**

例如：

- 部分场景使用廉价模型
- 高难度任务使用高端模型

# 5 接口需求（Input / Output Specifications）

​	本章规定 AstraChat 提供的标准化 API 接口，包括输入参数、输出参数、结构化错误格式、Token 消耗信息、人工转接信号（handoff）等内容。

外部业务系统（Web、小程序、后端服务）将通过 HTTP/REST 接口调用本系统，因此接口必须稳定、简洁、可扩展。

## **5.1 接口概述（API Overview）**

AstraChat 仅提供 **一个统一入口接口**：

```
POST /api/chat
```

该接口通过 API Gateway 暴露，对接后端 Lambda（AstraChatHandler）。

特性：

- 请求体为 JSON  
- 使用 HTTPS 传输  
- 返回结构化 JSON  
- 支持幂等  
- 支持跨域（依据 CORS 配置）

## **5.2 请求格式（Request Format）**

### **5.2.1 基础格式（必填字段）**

```js
POST /api/chat
Content-Type: application/json

{
  "userId": "string",
  "message": "string",
  "metadata": { ... }   // 可选
}
```

字段说明：

| 字段     | 类型   | 必填 | 描述           |
| -------- | ------ | ---- | -------------- |
| userId   | string | 是   | 用户唯一标识   |
| message  | string | 是   | 用户输入内容   |
| metadata | object | 否   | 业务方扩展字段 |

### **5.2.2 可选扩展字段（未来版本）**

| 字段      | 类型   | 描述             |
| --------- | ------ | ---------------- |
| imageUrl  | string | 图像输入（未来） |
| audioUrl  | string | 语音输入（未来） |
| sessionId | string | 指定会话         |

### **5.2.3 非法输入要求**

以下情况必须返回结构化错误：

- 缺少 `userId`
- 缺少 `message`
- message 非字符串
- JSON 解析失败

## **5.3 响应格式（Response Format）**

统一格式：

```json
{
  "success": true/false,
  "traceId": "string",
  "data": { ... },
  "error": { ... },
  "handoff": { ... }
}
```

### **5.3.1 正常响应（LLM 处理成功）**

```json
{
  "success": true,
  "traceId": "req_20250102_abcdef",
  "data": {
    "answer": "您好，我在这里为您服务。"
  }
}
```

### **5.3.2 人工客服转接（Handoff Response）**

```json
{
  "success": true,
  "traceId": "req_20250102_abcdef",
  "handoff": {
    "required": true,
    "reason": "LOW_CONFIDENCE",
    "message": "系统无法理解您的问题，已转接人工客服。"
  }
}
```

### **5.3.3 错误响应（Error Response）**

```json
{
  "success": false,
  "traceId": "req_20250102_abcdef",
  "error": {
    "code": "LLM_TIMEOUT",
    "message": "模型响应超时，请稍后再试"
  }
}
```

### **5.3.4 Token 消耗信息**

为支持企业级成本监控与模型调用分析，系统应支持在响应中返回 Token 消耗数据（由 Provider 层生成）。

当业务开启成本监控模式之后，响应格式如下：

```json
{
  "success": true,
  "traceId": "req_20250102_abcdef",
  "data": {
    "answer": "这是 AI 的回复。",
    "usage": {
      "promptTokens": 128,
      "completionTokens": 42,
      "totalTokens": 170
    }
  }
}
```

字段说明：

| 字段             | 描述                        |
| ---------------- | --------------------------- |
| promptTokens     | 输入 Prompt 使用的 Token 数 |
| completionTokens | 模型输出 Token 数           |
| totalTokens      | prompt + completion         |

要求：

1. Token 信息由 **Provider 层** 负责收集与写入  
2. **默认不返回 usage 字段**（节省网络带宽）  
3. Token 必须写入 CloudWatch 供后台分析  
4. 业务方可通过配置启用返回 token usage  

对于部分模型在错误时仍返回 usage 的情况，系统可在 error 区域附带 usage 字段（非强制）。

## **5.4 接口行为（Functional Behavior）**

### **5.4.1 AI 直答流程**
输入 message → 调模型 → 返回 answer。

### **5.4.2 RAG 流程**
检索知识库 → 拼接上下文 → 调 LLM → 返回增强回答。

### **5.4.3 工具调用流程**
示例输入：

```txt
"帮我查一下订单 12345"
```

系统行为：

1. DecisionModule 检测到“订单”意图
2. ToolsModule 调用订单 API
3. Provider 将结构化结果转成自然语言
4. 返回 answer

### **5.4.4 人工客服转接流程**
触发条件：

- 用户主动请求
- 工具调用失败
- 模型置信度低
- 敏感场景（投诉、退款等）

调用方需要根据 `handoff.required` 判断是否转人工。

### **5.4.5 Token 统计与记录机制**

系统必须：

- 在 Provider 层读取模型返回的 usage  
- 将 token 使用情况写入：  

  ```json
  ctx.llm.usage = {
    promptTokens: ...,
    completionTokens: ...,
    totalTokens: ...
  }
  ```

- 日志模块必须同步记录 token 用量  
- 若业务配置开启，必须在响应 data.usage 中回传  

Token 数据主要用于：

- 成本分析  
- Prompt 优化  
- 限额控制  
- 企业版本的计费系统

## 5.5 安全与认证要求（Security Requirements）

### 5.5.1 请求必须使用 HTTPS

禁止明文 HTTP。

### 5.5.2 调用方必须携带授权信息（未来版本）

例如：

```
Authorization: Bearer <token>
```

可扩展为 API Key 或 JWT。

### **5.5.3 系统不得返回敏感内部信息**

例如：

- Lambda 内路径
- DynamoDB 表名
- API 密钥
- 详细异常堆栈

## **5.6 错误分类（Error Taxonomy）**

系统内部必须将错误归类为：

| 类别         | 描述                   |
| ------------ | ---------------------- |
| 用户输入错误 | 输入缺失、格式无效     |
| 模型错误     | LLM API 超时、拒绝服务 |
| 工具调用错误 | 外部业务接口失败       |
| 系统错误     | 内部异常、依赖崩溃     |
| 安全错误     | 无权限或非法访问       |

## **5.7 版本兼容性要求（Versioning Requirements）**

### **5.7.1 系统必须保持 API 向后兼容**

新增字段必须为可选字段，不得破坏兼容性。

### **5.7.2 API 重大变更必须采用 versioning 机制**

例如：

```
/api/v2/chat
```

# 6. 数据需求（Data Requirements）

本章定义 AstraChat 系统所需的数据结构，包括存储于 DynamoDB 的会话数据、存储于 S3 的知识库文件格式、日志记录格式、工具调用数据结构、Token 消耗记录结构等。

所有数据格式必须满足以下要求：

- 结构化  
- 可扩展  
- 可版本化  
- 兼容未来多业务场景  

## **6.1 DynamoDB 数据设计**

AstraChat 使用 DynamoDB 作为长期存储，用于：

- 记录用户会话历史  
- 记录人工客服（handoff）相关信息  
- 存储系统对话摘要  
- 记录 token 消耗（可选）

### **6.1.1 表：astra_chat_sessions（会话历史）**

用于存储用户多轮对话的摘要信息。

### **主键设计**
| 字段           | 类型   | 描述                       |
| -------------- | ------ | -------------------------- |
| userId (PK)    | String | 用户唯一标识               |
| sessionId (SK) | String | 会话唯一标识（可自动生成） |

> 若简化为单会话模式，可仅使用 userId 作为主键。

---

### **字段设计**
| 字段                 | 类型      | 描述                                  |
| -------------------- | --------- | ------------------------------------- |
| history              | List<Map> | 对话摘要列表                          |
| model                | String    | 使用的模型名称，如 gpt-4o, claude-3   |
| updatedAt            | Number    | 时间戳                                |
| totalTokens          | Number    | 累计 Token 消耗（可选，用于成本分析） |
| lastUserMessage      | String    | 最近一条用户消息（便于人工查看）      |
| lastAssistantMessage | String    | 最近一次 AI 回复                      |

---

### **history 元素结构：**

```json
{
  "role": "user" | "assistant",
  "content": "文本摘要",
  "timestamp": 1735892332,
  "tokens": 42
}
```

要求：

- 保存摘要而不是全量内容（降低成本）  
- tokens 字段用于分析 token 分布  

### **6.1.2 表：astra_chat_handoff（人工客服转接记录）**

当系统进入 handoff 时，必须记录，以便人工客服端读取历史。

### **主键设计**

| 字段           | 类型   | 描述                  |
| -------------- | ------ | --------------------- |
| handoffId (PK) | String | 自动生成的转接事件 ID |

---

### **字段设计**

| 字段            | 类型      | 描述                                              |
| --------------- | --------- | ------------------------------------------------- |
| userId          | String    | 用户 ID                                           |
| sessionId       | String    | 会话 ID                                           |
| reason          | String    | LOW_CONFIDENCE / USER_REQUESTED / TOOL_FAILURE 等 |
| timestamp       | Number    | 转人工时间                                        |
| historySnapshot | List<Map> | 截取的对话摘要列表                                |
| lastMessage     | String    | 引发转接的用户消息                                |
| metadata        | Map       | 业务系统扩展参数                                  |

### **6.1.3 表：astra_chat_usage（Token 消耗记录，未来版本）**

用于企业版计费、成本监控。

### **主键**

| 字段         | 类型   | 描述          |
| ------------ | ------ | ------------- |
| usageId (PK) | String | token 记录 ID |

---

### **字段**

| 字段             | 类型   | 描述         |
| ---------------- | ------ | ------------ |
| userId           | String | 用户 ID      |
| sessionId        | String | 会话 ID      |
| traceId          | String | 请求唯一标识 |
| promptTokens     | Number | 输入 token   |
| completionTokens | Number | 输出 token   |
| totalTokens      | Number | 总 token     |
| model            | String | 使用的模型   |
| timestamp        | Number | 调用时间     |

## **6.2 S3 知识库数据结构（用于 RAG）**

AstraChat 的知识库（RAG）采用 S3 存储，结构需要支持：

- 多文档  
- 多语言  
- 文档版本  
- 分类  

### **6.2.1 Bucket 结构**

```
astra-chat-knowledge-base/
    ├── docs/
    │     ├── general/
    │     │     ├── intro_v1.md
    │     │     ├── intro_v2.md
    │     ├── products/
    │     │     ├── productA_overview.md
    │     │     ├── productB_guide.md
    │     └── faq/
    │           ├── faq_001.md
    │           ├── faq_002.md
    ├── embeddings/
    │     ├── intro_v2.json
    │     ├── faq_001.json
    └── config/
           ├── rag_settings.json
```

这允许：

- 文档按业务类型归类  
- embedding 文件与文档同名  
- 未来切换向量数据库  
- 文档自动加载  

### **6.2.2 文档文件结构（Markdown / Text）**

RAG 文档采用 markdown 存储：

```
# 产品A介绍
A 产品是一款……

## 功能说明
1. …
2. …

## 常见问题
Q: …
A: …
```

文档格式必须：

- 清晰分段  
- 标题结构化  
- 方便分段 embedding  

### **6.2.3 embedding 文件结构**

若未来不用向量数据库，可直接在 S3 中存储 embedding：

```
{
  "documentId": "productA_overview",
  "chunks": [
    {
      "text": "产品A是一款……",
      "embedding": [0.12, -0.33, ...]
    },
    ...
  ]
}
```

## **6.3 系统内部数据结构（Context Object）**

在 Pipeline 中传递的 ctx 结构必须统一，类似 ADAS 的“信号帧”。

### **6.3.1 Context 标准结构**

```
ctx = {
  traceId: "string",
  user: { userId, metadata },
  input: { message, rawEvent },
  session: { history, sessionId },
  rag: { documents, contextText },
  route: "LLM_DIRECT | LLM_WITH_RAG | TOOL | HANDOFF",
  llm: {
    answer: "string",
    usage: {
      promptTokens,
      completionTokens,
      totalTokens
    }
  },
  tool: { result, toolName },
  error: { code, message }
}
```

## **6.4 日志数据结构（CloudWatch Logs）**

日志必须结构化，便于检索 ELK/CloudWatch Insights。

示例：

```
{
  "traceId": "req_20250102_abcdef",
  "userId": "u123",
  "route": "LLM_WITH_RAG",
  "ragHits": 3,
  "promptTokens": 81,
  "completionTokens": 28,
  "totalTokens": 109,
  "latencyMs": 842,
  "timestamp": 1735892332
}
```

## **6.5 工具调用数据结构**

工具调用必须使用统一结构。

输入：

```
{
  "tool": "orderQuery",
  "args": {
    "orderId": "12345"
  }
}
```

输出：

```
{
  "success": true,
  "data": {
    "orderStatus": "已发货",
    "expectedArrival": "2025-01-03"
  }
}
```

错误：

```
{
  "success": false,
  "error": {
    "code": "TOOL_FAILURE",
    "message": "业务接口超时"
  }
}
```

# 7. 未来扩展需求（Future Enhancements）

本章说明 AstraChat 在 V1（当前版本）之外，为未来版本（V2 / V3 / 企业级版本）预留的扩展能力。  
这些功能不会在当前范围内实现，但系统设计必须为其保留接口、模块位置和架构扩展点。

## **7.1 图像理解（Vision Support）**

未来版本需要支持图片输入，包括但不限于：

### **7.1.1 OCR 文本识别**
- 从用户上传的图片中提取文本  
- 可用于票据识别、截图问答、产品说明书解读  

### **7.1.2 通用图像理解**
- 场景描述  
- UI 截图解释  
- 图表理解  

### **7.1.3 多模态 RAG（Retrieval-Augmented Generation for Images）**
- 将图片 embedding 纳入检索  
- 跨模态信息融合  

### **架构要求：**
- Pipeline 必须预留 `VisionModule` 扩展点  
- Provider 层需可支持多模态模型（如 GPT-4o、Claude Vision）  

## **7.2 语音支持（Speech Support）**

未来版本需支持语音输入与输出：

### **7.2.1 ASR（语音转文本）**
- 用户输入语音 → 系统自动转为 text  
- 可使用 Whisper API 或 AWS Transcribe  

### **7.2.2 TTS（文本转语音）**
- 系统可将回答通过语音播放给用户  
- 可使用 Amazon Polly 或 OpenAI TTS 模型  

### **7.2.3 多模态会话**
- Pipeline 中自动识别输入类型  
- 可同时处理文本 + 语音  

### **架构要求：**
- 在中间件层预留 `SpeechModule`  
- 允许请求中携带音频 URL 或 Base64  

## **7.3 多租户 SaaS 化（Multi-Tenant SaaS Architecture）**

为未来商业化做准备，AstraChat 需支持多租户模式：

### **7.3.1 租户隔离（Tenant Isolation）**
- 每个租户拥有独立的：
  - API Key  
  - 模型配置  
  - RAG 知识库  
  - 会话数据  

### **7.3.2 自定义配置**
租户可自定义：

- 系统 Prompt  
- 工具调用逻辑  
- Token 限额  
- 使用的模型类型（高端模型/经济模型）  

### **7.3.3 SaaS 计费与流量控制（未来）**
- Token 用量统计  
- 每次调用的可变成本  
- 包年/包月方案  

### **架构要求：**
- 添加 `tenantId` 到 Context 中  
- DynamoDB 和 S3 结构需支持租户隔离  
- Provider 层配置需按租户加载  

## **7.4 外部插件系统（Plugins / Extensibility）**

未来系统应让开发者自定义能力模块，例如：

- 自定义工具（Tool Plugins）  
- 自定义 RAG 检索方法  
- 自定义 Prompt 模板  
- 自定义业务规则决策模块  

需求：

- 插件热插拔  
- 最小化耦合  
- 统一接口格式  

## **7.5 工作流 / Agent 多步骤规划（Future Agent System）**

未来版本需支持：

- 多步骤推理  
- 自动工具选择  
- 任务规划（Planning）  
- Memory Graph（长期记忆图谱）  
- 复杂对话状态机  

## **7.6 企业版审计与合规（Enterprise Audit & Compliance）**

企业版需：

- 记录所有用户操作日志  
- Token 成本报表  
- 数据合规（GDPR / 隐私保护）  
- 敏感词检测  
- 内容审核  
